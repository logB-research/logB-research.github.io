<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> a distill-style blog post | You R. Name </title> <meta name="author" content="You R. Name"> <meta name="description" content="an example of a distill-style blog post and main elements"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://logb-research.github.io/blog/2021/distill/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> <style type="text/css">.fake-img{background:#bbb;border:1px solid rgba(0,0,0,0.1);box-shadow:0 0 4px rgba(0,0,0,0.1);margin-bottom:12px}.fake-img p{font-family:monospace;color:white;text-align:left;margin:12px 0;text-align:center;font-size:16px}</style> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "a distill-style blog post",
            "description": "an example of a distill-style blog post and main elements",
            "published": "May 22, 2021",
            "authors": [
              
              {
                "author": "Albert Einstein",
                "authorURL": "https://en.wikipedia.org/wiki/Albert_Einstein",
                "affiliations": [
                  {
                    "name": "IAS, Princeton",
                    "url": ""
                  }
                ]
              },
              
              {
                "author": "Boris Podolsky",
                "authorURL": "https://en.wikipedia.org/wiki/Boris_Podolsky",
                "affiliations": [
                  {
                    "name": "IAS, Princeton",
                    "url": ""
                  }
                ]
              },
              
              {
                "author": "Nathan Rosen",
                "authorURL": "https://en.wikipedia.org/wiki/Nathan_Rosen",
                "affiliations": [
                  {
                    "name": "IAS, Princeton",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">You</span> R. Name </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>a distill-style blog post</h1> <p>an example of a distill-style blog post and main elements</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#equations">Equations</a> </div> <div> <a href="#citations">Citations</a> </div> <div> <a href="#footnotes">Footnotes</a> </div> <div> <a href="#code-blocks">Code Blocks</a> </div> <div> <a href="#interactive-plots">Interactive Plots</a> </div> <div> <a href="#layouts">Layouts</a> </div> <div> <a href="#other-typography">Other Typography?</a> </div> </nav> </d-contents> <h1 id="kernel-trick-i">Kernel Trick I</h1> <h2 id="deep-convolutional-representations-in-rkhs">Deep Convolutional Representations in RKHS</h2> <h2 id="goal-">Goal 🚀</h2> <blockquote> <p>Fear not, those who delve into the maths of the kernel trick, for its advent in deep learning is coming.</p> <p>In this blog post, we focus on the Convolutional Kernel Network (CKN) architecture introduced in <d-cite key="mairal2016endtoend"></d-cite> and present its guiding principles and main components. This model opened a new line of research by demonstrating the benefits of the kernel trick for deep convolutional representations. For a more complete picture, we invite the reader to refer to the original paper <d-cite key="mairal2016endtoend"></d-cite>.</p> </blockquote> <h2 id="kernel-trick">Kernel Trick</h2> <p>We provide below a simple definition of the kernel trick. For the interested reader, more details about the kernel trick can be found in <d-cite key="scholkopf2000kerneltrick"></d-cite> and the <a href="https://mva-kernel-methods.github.io/course-2023-2024/static_files/materials/slides.pdf" rel="external nofollow noopener" target="_blank">slides</a> of <a href="https://lear.inrialpes.fr/people/mairal/" rel="external nofollow noopener" target="_blank">Julien Mairal</a> and <a href="https://jpvert.github.io/" rel="external nofollow noopener" target="_blank">Jean-Philippe Vert</a> contain all one needs to know about kernel methods. Let $\mathcal{H}$ be a high-dimensional feature space and $\phi\colon \mathcal{X} \to \mathcal{H}$ a mapping. In the situation where inputs are first mapped to $\mathcal{H}$ with $\phi$ and then compared using the inner product $\langle \phi(x), \phi(x’)\rangle_{\mathcal{H}}$, the kernel trick enables us to directly evaluate such pairwise comparison by kernel evaluation, i.e., \(K(x, x') = \langle \phi(x), \phi(x')\rangle_{\mathcal{H}}.\)</p> <h3 id="box">BOX</h3> <p>Let us consider a set $\mathcal{X}$, a p.d. kernel $K : \mathcal{X}\times\mathcal{X} \to \mathbb{R}$, its associated RKHS $\mathcal{H}$ and its associated mapping fonction $\phi : \mathcal{X} \to \mathbb R$, i.e. the function such that $\forall x,x’,~K(x,x’) = \langle \phi(x),\phi(x’) \rangle_{\mathcal{H}}$.</p> <p>We recall below the notions of homogeneous dot product kernels that will be useful in the following. Let us consider some function $\kappa : \mathbb{R}\to\mathbb{R}$. A dot product kernel is a p.d. kernel $K : \mathcal{X}\times\mathcal{X} \to \mathbb{R}$ defined as \(\forall x,x' \in \mathcal{X},~ K(x,x') = \kappa(\langle x,x'\rangle).\) We also define homogeneous dot product kernels as \(\forall x,x' \in \mathcal{X},~ K(x,x') = \lVert x \rVert\lVert x'\rVert \kappa \left(\left\langle \frac{x}{\lVert x \rVert},\frac{x'}{\lVert x'\rVert}\right\rangle\right).\)</p> <p>If $\kappa$ has some regular properties (see <d-cite key="mairal2016endtoend"></d-cite>), we can use homogeneous dot product kernels to represent local image neighborhoods in $\mathcal{H}$.</p> <p>A lot of these kernels exist, see <d-cite key="mairal2016endtoend"></d-cite> for details. These include the \textit{exponential} dot product kernel $K_{\exp}(x,y) = \text{e}^{\beta(\langle x,x’\rangle -1)} = \text{e}^{-\frac{\beta}{2}\lVert x-x’ \rVert_2^2}$, where $\beta &gt; 0$. When $\displaystyle\beta = \frac{1}{\sigma^2}$, we recover the well-known Gaussian Kernel. By the way, the arguments of the chosen kernels can be learned during model training!</p> <h2 id="1-convolutional-kernel-network-in-depth">1. Convolutional Kernel Network in depth</h2> <h3 id="11-mathematical-insights-and-computability">1.1. Mathematical insights and computability</h3> <p>Kernel trick here, kernel trick there… But can we really compute this kernel trick in practice ?</p> <p>Let us define mathematically an image as a mapping $I_0 : \Omega_0 \to \mathbb{R}^{3}$ (as an image has $3$ color channels). If $x$ and $x’$ are two patches extracted from $I_0$ we can get $\phi_1(x)$ and $\phi_1(x’)$, their representation in $\mathcal{H}$, thanks to the kernel trick ! But, $\mathcal{H}$ is an <strong><em>infinite</em></strong> dimensional space, so how to deal with it in practice? <img class="emoji" title=":dizzy_face:" alt=":dizzy_face:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f635.png" height="20" width="20"></p> <p>No panic, our friend Nyström is here to help! Nyström’s method aims to approximate $\phi_1(x)$ and $\phi_1(x’)$ by their projection $\psi_1(x)$ and $\psi_1(x’)$ onto a <strong><em>finite</em></strong> dimensional subspace $\mathcal{F}$ (see the figure below).</p> <p><img src="https://hackmd.io/_uploads/HJYIo0vWC.png" alt="Nystrom"></p> <p>The subspace $\mathcal{F}$ is defined as $\mathcal{F} = \text{span}(z_1,\dots,z_p)$, where $(z_i)_{i\in{1\dots p}}$ are anchor points, of unit-norm. $Z = {z_1,\dots,z_p}$ are the parameters of the layer in the sense that optimizing the layer means optimizing $\mathcal{F}$. The subspace $\mathcal{F}$ can be optimized in both a <em>supervised</em> (with backpropagation rules) or an <em>unsupervised</em> way (by minimzing projection residuals with spherical KMeans), see <d-cite key="mairal2016endtoend"></d-cite>.</p> <h3 id="3-the-convolutional-kernel-network">3. The Convolutional Kernel Network</h3> <p>We can therefore construct our Convolutional Kernel Layer in three steps.</p> <ol> <li>The idea is that we first extract patches $x$ from the image $I_0$.</li> </ol> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">extract_2d_patches</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
        <span class="n">h</span><span class="p">,</span><span class="n">w</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">filter_size</span>
        <span class="n">batch_size</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span>
        <span class="n">unfolded_x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">lib</span><span class="p">.</span><span class="n">stride_tricks</span><span class="p">.</span><span class="nf">sliding_window_view</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">))</span>
        <span class="n">unfolded_x</span> <span class="o">=</span> <span class="n">unfolded_x</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">patch_dim</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">unfolded_x</span>

<span class="k">def</span> <span class="nf">sample_patches</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x_in</span><span class="p">,</span> <span class="n">n_sampling_patches</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
        <span class="n">patches</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">extract_2d_patches</span><span class="p">(</span><span class="n">x_in</span><span class="p">)</span>
        <span class="n">n_sampling_patches</span> <span class="o">=</span> <span class="nf">min</span><span class="p">(</span><span class="n">patches</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">n_sampling_patches</span><span class="p">)</span>
        <span class="n">patches</span> <span class="o">=</span> <span class="n">patches</span><span class="p">[:</span><span class="n">n_sampling_patches</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">patches</span>
</code></pre></div></div> <ol> <li> <table> <tbody> <tr> <td>Then, we normalize and convolve them as $\lVert x \rVert\kappa\left(Z^\top \displaystyle\frac{x}{</td> <td> </td> <td>x</td> <td> </td> <td>}\right)$ and compute the approximation as $\psi(x) = \lVert x \rVert\kappa\left(Z^\top Z\right)^{-1/2}\kappa\left(Z^\top \displaystyle\frac{x}{</td> <td> </td> <td>x</td> <td> </td> <td>}\right)$ by applying the linear transform $\kappa\left(Z^\top Z\right)^{-1/2}$ at every pixel location,</td> </tr> </tbody> </table> </li> </ol> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">conv_layer</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="n">x_in</span><span class="p">):</span>
        <span class="n">patch_norm</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">clip</span><span class="p">(</span><span class="nf">conv2d_scipy</span><span class="p">(</span><span class="n">x_in</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span><span class="n">self</span><span class="p">.</span><span class="n">ones</span><span class="p">,</span><span class="n">bias</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">padding</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">padding</span><span class="p">,</span><span class="n">dilation</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">dilation</span><span class="p">,</span>
                <span class="n">groups</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">groups</span><span class="p">),</span><span class="n">a_min</span><span class="o">=</span><span class="n">EPS</span><span class="p">,</span><span class="n">a_max</span><span class="o">=</span><span class="bp">None</span><span class="p">))</span>
        <span class="n">x_out</span> <span class="o">=</span> <span class="nf">conv2d_scipy</span><span class="p">(</span><span class="n">x_in</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">bias</span><span class="p">,(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span>
                        <span class="n">self</span><span class="p">.</span><span class="n">padding</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">dilation</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">groups</span><span class="p">)</span>
        <span class="n">x_out</span> <span class="o">=</span> <span class="n">x_out</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="nf">clip</span><span class="p">(</span><span class="n">patch_norm</span><span class="p">,</span><span class="n">a_min</span><span class="o">=</span><span class="n">EPS</span><span class="p">,</span><span class="n">a_max</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
        <span class="n">x_out</span> <span class="o">=</span> <span class="n">patch_norm</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="nf">kappa</span><span class="p">(</span><span class="n">x_out</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x_out</span>
    
<span class="k">def</span> <span class="nf">mult_layer</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x_in</span><span class="p">,</span> <span class="n">lintrans</span><span class="p">):</span>
        <span class="n">batch_size</span><span class="p">,</span> <span class="n">in_c</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="n">x_in</span><span class="p">.</span><span class="n">shape</span>
        <span class="n">x_out</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">matmul</span><span class="p">(</span>
            <span class="n">np</span><span class="p">.</span><span class="nf">tile</span><span class="p">(</span><span class="n">lintrans</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> 
            <span class="n">x_in</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">in_c</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">x_out</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">in_c</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span>
</code></pre></div></div> <ol> <li>We can therefore compute the pooling operations. Note that gaussian linear pooling is defined as \(\displaystyle I_1(x) = \int_{x'\in\Omega_0} M_1(x') \text{e}^{-\beta\lVert x-x'\rVert_2^2}\text{d}x'\) where $M_1$ is the “feature map” after the operation of step 2. That is why, we can interpret the pooling operation as a “convolution” operation.</li> </ol> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">pool_layer</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="n">x_in</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">subsampling</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">x_in</span>
        <span class="n">x_out</span> <span class="o">=</span> <span class="nf">conv2d_scipy</span><span class="p">(</span><span class="n">x_in</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">pooling_filter</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> 
            <span class="n">stride</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">subsampling</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">subsampling</span><span class="p">,</span> 
            <span class="n">groups</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">out_channels</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x_out</span>
</code></pre></div></div> <p>Here’s a global figure that summarizes all these operations, and thus the construction of a Convolutional Kernel Layer.</p> <p><img src="https://hackmd.io/_uploads/SkBrn1OWC.png" alt="CKN"></p> <p>After these operations, we have constructed a “feature map” $I_1 : \Omega_1 \to \mathbb{R}^{p_1}$, that can be re-used. We can now build a <strong>Convolutional Kernel Network</strong> by stacking Convolutional Kernel Layers, and we will have a <em>representation</em> of the image at the output.</p> <h2 id="2-cnn-vs-ckn">2. CNN vs. CKN</h2> <p>In <d-cite key="bietti2018group"></d-cite>, it is shown that CKNs contain a large class of CNNs with smooth homogeneous activation functions.</p> <p><img src="https://hackmd.io/_uploads/SJEKiRDZR.png" alt="CNN"></p> <p>The similarities and differences between CKN and CNN are well illustrated in Figures~\ref{fig:CKN2} and \ref{fig:CNN}.</p> <p>On the one hand, A CNN of $K$ layer can be represented by its output $f_{\text{CNN}}(x)$, if $x$ is the input, as :</p> \[f_{\text{CNN}}(x) = \gamma_K(\sigma_K(W_K\dots \gamma_2(\sigma_2(W_2\gamma_1(\sigma_1(W_1x))\dots))\] <p>where $(W_k)_k$ represent the convolution operations, $(\sigma_k)_k$ are pointwise non-linear functions, (e.g., ReLU), and $(\gamma_k)_k$ represent the pooling operations (see \cite{paulin2016convolutional}).</p> <p>On the other hand, A CKN of $K$ layer can be represented by its output $f_{\text{CKN}}(x)$, if $x$ is the input, as :</p> \[f_{\text{CKN}}(x) = \gamma_K(\sigma_K(W_K(P_K\dots \gamma_2(\sigma_2(W_2(P_2(\gamma_1(\sigma_1(W_1(P_1(x))\dots))\] <p>where $(P_k)_k$ represent the patch extractions, $(W_k)_k$ the convolution operations, $(\sigma_k)_k$ the kernel operations (which allows us to learn non-linearity in the RKHS), and $(\gamma_k)_k$ the pooling operations.</p> <h2 id="desktop_computer-for-the-interesting-reader"> <img class="emoji" title=":desktop_computer:" alt=":desktop_computer:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f5a5.png" height="20" width="20"> For the interesting reader</h2> <p>We provide an open-source implementation of the CKN architecture in pure numpy <a href="https://github.com/ozekri/CKN_from_Scratch" rel="external nofollow noopener" target="_blank">here</a> to better understand how things work without having to read pages of documentation of modern deep learning framework such as <code class="language-plaintext highlighter-rouge">PyTorch</code>, <code class="language-plaintext highlighter-rouge">TensorFlow</code> or <code class="language-plaintext highlighter-rouge">JAX</code>. For practical usage, the original implementation can be found <a href="https://github.com/claying/CKN-Pytorch-image" rel="external nofollow noopener" target="_blank">here</a>.</p> <p>For any further questions, please feel free to contact the authors by mail!</p> <h2 id="acknowledgments">Acknowledgments</h2> <p>We heartfully thank the professors of the <a href="https://mva-kernel-methods.github.io/course-2023-2024/" rel="external nofollow noopener" target="_blank">Kernel Methods course</a> of the <a href="https://www.master-mva.com/" rel="external nofollow noopener" target="_blank">MVA Master</a> : Prof. <a href="https://lear.inrialpes.fr/people/mairal/" rel="external nofollow noopener" target="_blank">Julien Mairal</a>, Prof. <a href="https://jpvert.github.io/" rel="external nofollow noopener" target="_blank">Jean-Philippe Vert</a>, Prof. <a href="https://michaelarbel.github.io/" rel="external nofollow noopener" target="_blank">Michel Arbel</a>, Prof. <a href="https://www.di.ens.fr/~rudi/" rel="external nofollow noopener" target="_blank">Alessandro Rudi</a>. A special mention to Prof. <a href="https://lear.inrialpes.fr/people/mairal/" rel="external nofollow noopener" target="_blank">Julien Mairal</a> for proofreading this blog post !</p> <h2 id="equations">Equations</h2> <p>This theme supports rendering beautiful math in inline and display modes using <a href="https://www.mathjax.org/" rel="external nofollow noopener" target="_blank">MathJax 3</a> engine. You just need to surround your math expression with <code class="language-plaintext highlighter-rouge">$$</code>, like <code class="language-plaintext highlighter-rouge">$$ E = mc^2 $$</code>. If you leave it inside a paragraph, it will produce an inline expression, just like \(E = mc^2\).</p> <p>To use display mode, again surround your expression with <code class="language-plaintext highlighter-rouge">$$</code> and place it as a separate paragraph. Here is an example:</p> \[\left( \sum_{k=1}^n a_k b_k \right)^2 \leq \left( \sum_{k=1}^n a_k^2 \right) \left( \sum_{k=1}^n b_k^2 \right)\] <p>Note that MathJax 3 is <a href="https://docs.mathjax.org/en/latest/upgrading/whats-new-3.0.html" rel="external nofollow noopener" target="_blank">a major re-write of MathJax</a> that brought a significant improvement to the loading and rendering speed, which is now <a href="http://www.intmath.com/cg5/katex-mathjax-comparison.php" rel="external nofollow noopener" target="_blank">on par with KaTeX</a>.</p> <hr> <h2 id="citations">Citations</h2> <p>Citations are then used in the article body with the <code class="language-plaintext highlighter-rouge">&lt;d-cite&gt;</code> tag. The key attribute is a reference to the id provided in the bibliography. The key attribute can take multiple ids, separated by commas.</p> <p>The citation is presented inline like this: <d-cite key="paulin2016convolutional"></d-cite> (a number that displays more information on hover). If you have an appendix, a bibliography is automatically created and populated in it.</p> <p>Distill chose a numerical inline citation style to improve readability of citation dense articles and because many of the benefits of longer citations are obviated by displaying more information on hover. However, we consider it good style to mention author last names if you discuss something at length and it fits into the flow well — the authors are human and it’s nice for them to have the community associate them with their work.</p> <hr> <h2 id="footnotes">Footnotes</h2> <p>Just wrap the text you would like to show up in a footnote in a <code class="language-plaintext highlighter-rouge">&lt;d-footnote&gt;</code> tag. The number of the footnote will be automatically generated.<d-footnote>This will become a hoverable footnote.</d-footnote></p> <hr> <h2 id="code-blocks">Code Blocks</h2> <p>Syntax highlighting is provided within <code class="language-plaintext highlighter-rouge">&lt;d-code&gt;</code> tags. An example of inline code snippets: <code class="language-plaintext highlighter-rouge">&lt;d-code language="html"&gt;let x = 10;&lt;/d-code&gt;</code>. For larger blocks of code, add a <code class="language-plaintext highlighter-rouge">block</code> attribute:</p> <d-code block="" language="javascript"> var x = 25; function(x) { return x * x; } </d-code> <p><strong>Note:</strong> <code class="language-plaintext highlighter-rouge">&lt;d-code&gt;</code> blocks do not look good in the dark mode. You can always use the default code-highlight using the <code class="language-plaintext highlighter-rouge">highlight</code> liquid tag:</p> <figure class="highlight"><pre><code class="language-javascript" data-lang="javascript"><span class="kd">var</span> <span class="nx">x</span> <span class="o">=</span> <span class="mi">25</span><span class="p">;</span>
<span class="kd">function</span><span class="p">(</span><span class="nx">x</span><span class="p">)</span> <span class="p">{</span>
<span class="k">return</span> <span class="nx">x</span> <span class="err">\</span><span class="o">*</span> <span class="nx">x</span><span class="p">;</span>
<span class="p">}</span></code></pre></figure> <hr> <h2 id="interactive-plots">Interactive Plots</h2> <p>You can add interative plots using plotly + iframes <img class="emoji" title=":framed_picture:" alt=":framed_picture:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f5bc.png" height="20" width="20"></p> <div class="l-page"> <iframe src="/assets/plotly/demo.html" frameborder="0" scrolling="no" height="500px" width="100%" style="border: 1px dashed grey;"></iframe> </div> <p>The plot must be generated separately and saved into an HTML file. To generate the plot that you see above, you can use the following code snippet:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">plotly.express</span> <span class="k">as</span> <span class="n">px</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span>
<span class="sh">'</span><span class="s">https://raw.githubusercontent.com/plotly/datasets/master/earthquakes-23k.csv</span><span class="sh">'</span>
<span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">px</span><span class="p">.</span><span class="nf">density_mapbox</span><span class="p">(</span>
<span class="n">df</span><span class="p">,</span>
<span class="n">lat</span><span class="o">=</span><span class="sh">'</span><span class="s">Latitude</span><span class="sh">'</span><span class="p">,</span>
<span class="n">lon</span><span class="o">=</span><span class="sh">'</span><span class="s">Longitude</span><span class="sh">'</span><span class="p">,</span>
<span class="n">z</span><span class="o">=</span><span class="sh">'</span><span class="s">Magnitude</span><span class="sh">'</span><span class="p">,</span>
<span class="n">radius</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="n">center</span><span class="o">=</span><span class="nf">dict</span><span class="p">(</span><span class="n">lat</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">lon</span><span class="o">=</span><span class="mi">180</span><span class="p">),</span>
<span class="n">zoom</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="n">mapbox_style</span><span class="o">=</span><span class="sh">"</span><span class="s">stamen-terrain</span><span class="sh">"</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="nf">write_html</span><span class="p">(</span><span class="sh">'</span><span class="s">assets/plotly/demo.html</span><span class="sh">'</span><span class="p">)</span></code></pre></figure> <hr> <h2 id="details-boxes">Details boxes</h2> <p>Details boxes are collapsible boxes which hide additional information from the user. They can be added with the <code class="language-plaintext highlighter-rouge">details</code> liquid tag:</p> <details><summary>Click here to know more</summary> <p>Additional details, where math \(2x - 1\) and <code class="language-plaintext highlighter-rouge">code</code> is rendered correctly.</p> </details> <hr> <h2 id="layouts">Layouts</h2> <p>The main text column is referred to as the body. It is the assumed layout of any direct descendants of the <code class="language-plaintext highlighter-rouge">d-article</code> element.</p> <div class="fake-img l-body"> <p>.l-body</p> </div> <p>For images you want to display a little larger, try <code class="language-plaintext highlighter-rouge">.l-page</code>:</p> <div class="fake-img l-page"> <p>.l-page</p> </div> <p>All of these have an outset variant if you want to poke out from the body text a little bit. For instance:</p> <div class="fake-img l-body-outset"> <p>.l-body-outset</p> </div> <div class="fake-img l-page-outset"> <p>.l-page-outset</p> </div> <p>Occasionally you’ll want to use the full browser width. For this, use <code class="language-plaintext highlighter-rouge">.l-screen</code>. You can also inset the element a little from the edge of the browser by using the inset variant.</p> <div class="fake-img l-screen"> <p>.l-screen</p> </div> <div class="fake-img l-screen-inset"> <p>.l-screen-inset</p> </div> <p>The final layout is for marginalia, asides, and footnotes. It does not interrupt the normal flow of <code class="language-plaintext highlighter-rouge">.l-body</code> sized text except on mobile screen sizes.</p> <div class="fake-img l-gutter"> <p>.l-gutter</p> </div> <hr> <h2 id="other-typography">Other Typography?</h2> <p>Emphasis, aka italics, with <em>asterisks</em> (<code class="language-plaintext highlighter-rouge">*asterisks*</code>) or <em>underscores</em> (<code class="language-plaintext highlighter-rouge">_underscores_</code>).</p> <p>Strong emphasis, aka bold, with <strong>asterisks</strong> or <strong>underscores</strong>.</p> <p>Combined emphasis with <strong>asterisks and <em>underscores</em></strong>.</p> <p>Strikethrough uses two tildes. <del>Scratch this.</del></p> <ol> <li>First ordered list item</li> <li>Another item ⋅⋅* Unordered sub-list.</li> <li>Actual numbers don’t matter, just that it’s a number ⋅⋅1. Ordered sub-list</li> <li>And another item.</li> </ol> <p>⋅⋅⋅You can have properly indented paragraphs within list items. Notice the blank line above, and the leading spaces (at least one, but we’ll use three here to also align the raw Markdown).</p> <p>⋅⋅⋅To have a line break without a paragraph, you will need to use two trailing spaces.⋅⋅ ⋅⋅⋅Note that this line is separate, but within the same paragraph.⋅⋅ ⋅⋅⋅(This is contrary to the typical GFM line break behaviour, where trailing spaces are not required.)</p> <ul> <li> <p>Unordered list can use asterisks</p> </li> <li> <p>Or minuses</p> </li> <li> <p>Or pluses</p> </li> </ul> <p><a href="https://www.google.com" rel="external nofollow noopener" target="_blank">I’m an inline-style link</a></p> <p><a href="https://www.google.com" title="Google's Homepage" rel="external nofollow noopener" target="_blank">I’m an inline-style link with title</a></p> <p><a href="https://www.mozilla.org" rel="external nofollow noopener" target="_blank">I’m a reference-style link</a></p> <p><a href="http://slashdot.org" rel="external nofollow noopener" target="_blank">You can use numbers for reference-style link definitions</a></p> <p>Or leave it empty and use the <a href="http://www.reddit.com" rel="external nofollow noopener" target="_blank">link text itself</a>.</p> <p>URLs and URLs in angle brackets will automatically get turned into links. http://www.example.com or <a href="http://www.example.com" rel="external nofollow noopener" target="_blank">http://www.example.com</a> and sometimes example.com (but not on Github, for example).</p> <p>Some text to show that the reference links can follow later.</p> <p>Here’s our logo (hover to see the title text):</p> <p>Inline-style: <img src="https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png" alt="alt text" title="Logo Title Text 1"></p> <p>Reference-style: <img src="https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png" alt="alt text" title="Logo Title Text 2"></p> <p>Inline <code class="language-plaintext highlighter-rouge">code</code> has <code class="language-plaintext highlighter-rouge">back-ticks around</code> it.</p> <div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">var</span> <span class="nx">s</span> <span class="o">=</span> <span class="dl">"</span><span class="s2">JavaScript syntax highlighting</span><span class="dl">"</span><span class="p">;</span>
<span class="nf">alert</span><span class="p">(</span><span class="nx">s</span><span class="p">);</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">s</span> <span class="o">=</span> <span class="sh">"</span><span class="s">Python syntax highlighting</span><span class="sh">"</span>
<span class="k">print</span> <span class="n">s</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>No language indicated, so no syntax highlighting.
But let's throw in a &lt;b&gt;tag&lt;/b&gt;.
</code></pre></div></div> <p>Colons can be used to align columns.</p> <table> <thead> <tr> <th>Tables</th> <th style="text-align: center">Are</th> <th style="text-align: right">Cool</th> </tr> </thead> <tbody> <tr> <td>col 3 is</td> <td style="text-align: center">right-aligned</td> <td style="text-align: right">$1600</td> </tr> <tr> <td>col 2 is</td> <td style="text-align: center">centered</td> <td style="text-align: right">$12</td> </tr> <tr> <td>zebra stripes</td> <td style="text-align: center">are neat</td> <td style="text-align: right">$1</td> </tr> </tbody> </table> <p>There must be at least 3 dashes separating each header cell. The outer pipes (|) are optional, and you don’t need to make the raw Markdown line up prettily. You can also use inline Markdown.</p> <table> <thead> <tr> <th>Markdown</th> <th>Less</th> <th>Pretty</th> </tr> </thead> <tbody> <tr> <td><em>Still</em></td> <td><code class="language-plaintext highlighter-rouge">renders</code></td> <td><strong>nicely</strong></td> </tr> <tr> <td>1</td> <td>2</td> <td>3</td> </tr> </tbody> </table> <blockquote> <p>Blockquotes are very handy in email to emulate reply text. This line is part of the same quote.</p> </blockquote> <p>Quote break.</p> <blockquote> <p>This is a very long line that will still be quoted properly when it wraps. Oh boy let’s keep writing to make sure this is long enough to actually wrap for everyone. Oh, you can <em>put</em> <strong>Markdown</strong> into a blockquote.</p> </blockquote> <p>Here’s a line for us to start with.</p> <p>This line is separated from the one above by two newlines, so it will be a <em>separate paragraph</em>.</p> <p>This line is also a separate paragraph, but… This line is only separated by a single newline, so it’s a separate line in the <em>same paragraph</em>.</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/2024-04-22-ckn.bib"></d-bibliography> <div id="giscus_thread" style="max-width: 800px; margin: 0 auto;"> <script>let giscusTheme=determineComputedTheme(),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"logB-research/logB-research.github.io","data-repo-id":"","data-category":"Comments","data-category-id":"","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 You R. Name. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>