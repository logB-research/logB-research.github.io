<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Kernel Trick I - Deep Convolutional Representations in RKHS | logB </title> <meta name="author" content="logB "> <meta name="description" content="Convolutional Kernel Networks"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://logb-research.github.io/blog/2024/ckn/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> <style type="text/css">.fake-img{background:#bbb;border:1px solid rgba(0,0,0,0.1);box-shadow:0 0 4px rgba(0,0,0,0.1);margin-bottom:12px}.fake-img p{font-family:monospace;color:white;text-align:left;margin:12px 0;text-align:center;font-size:16px}</style> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "Kernel Trick I - Deep Convolutional Representations in RKHS",
            "description": "Convolutional Kernel Networks",
            "published": "April 22, 2024",
            "authors": [
              
              {
                "author": "Oussama Zekri",
                "authorURL": "https://oussamazekri.fr",
                "affiliations": [
                  {
                    "name": "ENS Paris-Saclay",
                    "url": ""
                  }
                ]
              },
              
              {
                "author": "Ambroise Odonnat",
                "authorURL": "https://ambroiseodt.github.io/",
                "affiliations": [
                  {
                    "name": "Huawei Noah's Ark Lab",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">logB</span> </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Kernel Trick I - Deep Convolutional Representations in RKHS</h1> <p>Convolutional Kernel Networks</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#goal">Goal üöÄ</a> </div> <div> <a href="#kernel-trick-%EF%B8%8F">Kernel Trick üßô‚Äç‚ôÇÔ∏è</a> </div> <div> <a href="#convolutional-kernel-network-in-depth">Convolutional Kernel Network in-depth üîé</a> </div> <div> <a href="#cnn-vs-ckn-%EF%B8%8F">CNN vs. CKN ‚öîÔ∏è</a> </div> <div> <a href="#getting-your-hands-dirty-%EF%B8%8F">Getting your hands dirty üñ•Ô∏è</a> </div> <div> <a href="#acknowledgments">Acknowledgments üôèüèæ</a> </div> </nav> </d-contents> <h2 id="goal-"> <a id="goal"></a>Goal üöÄ</h2> <blockquote> <p>Fear not, those who delved into the maths of the kernel trick, for its advent in deep learning is coming.</p> </blockquote> <p>In this blog post, we focus on the Convolutional Kernel Network (CKN) architecture introduced in <d-cite key="mairal2016endtoend"></d-cite> and present its guiding principles and main components. The CKN opened a new line of research in deep learning by demonstrating the benefits of the kernel trick for deep convolutional representations. The goal of this blog is to provide a high level view of For a more complete picture, we invite the reader to refer to the original paper <d-cite key="mairal2016endtoend"></d-cite>.</p> <h2 id="kernel-trick-Ô∏è">Kernel Trick üßô‚Äç‚ôÇÔ∏è</h2> <p>We briefly recall the definition of the kernel trick. Let \(\mathcal{H}\) be a high-dimensional feature space and \(\varphi\colon \mathcal{X} \to \mathcal{H}\) a mapping. In the situation where inputs are first mapped to \(\mathcal{H}\) with \(\varphi\) and then compared using the inner product \(\langle \varphi(\mathbf{x}), \varphi(\mathbf{x}')\rangle_{\mathcal{H}}\), the kernel trick enables us to directly evaluate such pairwise comparison by kernel evaluation, i.e.,</p> \[\begin{equation*} K(\mathbf{x}, \mathbf{x}') = \langle \varphi(\mathbf{x}), \varphi(\mathbf{x}')\rangle_{\mathcal{H}} \end{equation*}\] <p>For the interested reader, more details can be found below or in <d-cite key="scholkopf2000kerneltrick"></d-cite>. In addition, the <a href="https://mva-kernel-methods.github.io/course-2023-2024/static_files/materials/slides.pdf" rel="external nofollow noopener" target="_blank">slides</a> of <a href="https://lear.inrialpes.fr/people/mairal/" rel="external nofollow noopener" target="_blank">Julien Mairal</a> and <a href="https://jpvert.github.io/" rel="external nofollow noopener" target="_blank">Jean-Philippe Vert</a> contain all one needs to know about kernel methods.</p> <details><summary>More details on Kernels <img class="emoji" title=":mag_right:" alt=":mag_right:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f50e.png" height="20" width="20"></summary> <p>Let us consider a set \(\mathcal{X}\), a p.d. kernel \(K : \mathcal{X}\times\mathcal{X} \to \mathbb{R}\), its associated RKHS \(\mathcal{H}\) and its associated mapping fonction \(\varphi : \mathcal{X} \to \mathbb R\), i.e. the function such that \(\forall \mathbf{x},\mathbf{x}',~K(x,x') = \langle \varphi(\mathbf{x}),\varphi(\mathbf{x}') \rangle_{\mathcal{H}}\).</p> <p>In the rest of this post, we‚Äôll be talking about CKNs, which use a particular type of kernel, namely dots product kernels. Let us consider some function \(\kappa : \mathbb{R}\to\mathbb{R}\). A dot product kernel is a p.d. kernel \(K : \mathcal{X}\times\mathcal{X} \to \mathbb{R}\) defined as \(\forall \mathbf{x},\mathbf{x}' \in \mathcal{X},~ K(\mathbf{x},\mathbf{x}') = \kappa(\langle \mathbf{x},\mathbf{x}'\rangle).\) We also define homogeneous dot product kernels as \(\forall \mathbf{x},\mathbf{x}' \in \mathcal{X},~ K(\mathbf{x},\mathbf{x}') = \lVert \mathbf{x} \rVert\lVert \mathbf{x}'\rVert \kappa \left(\left\langle \frac{\mathbf{x}}{\lVert \mathbf{x} \rVert},\frac{\mathbf{x}'}{\lVert \mathbf{x}'\rVert}\right\rangle\right).\)</p> <p>If \(\kappa\) has some regular properties (see <d-cite key="mairal2016endtoend"></d-cite>), we can use homogeneous dot product kernels to represent local image neighborhoods in \(\mathcal{H}\).</p> <p>A lot of these kernels exist, see <d-cite key="mairal2016endtoend"></d-cite> for details. These include the \textit{exponential} dot product kernel \(K_{\exp}(\mathbf{x},\mathbf{x}') = \text{e}^{\beta(\langle \mathbf{x},\mathbf{x}'\rangle -1)} = \text{e}^{-\frac{\beta}{2}\lVert \mathbf{x}-\mathbf{x}' \rVert_2^2}\), where \(\beta &gt; 0\). When \(\displaystyle\beta = \frac{1}{\sigma^2}\), we recover the well-known Gaussian Kernel. By the way, the arguments of the chosen kernels can be learned during model training!</p> </details> <p>A direct and very popular application of the kernel trick is SVM. It allows us to map data points from an initial space to a more abstract RKHS. In this way, we can move into spaces in which the data is represented in a linearly separable way (by a hyperplane). Here‚Äôs a short animation showing how the kernel trick can be used to map data initially contained in a 2D plane, to a larger space where they can be separated by a hyperplane.</p> <figure> <picture> <img src="/assets/img/blog_ckn/kernel_trick_colored.gif" class="img-fluid rounded z-depth-0" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>Of course, kernel trick can be used for much more than that, and in this post, we propose to show you how you can play with convolutional representations using kernel trick.</p> <h2 id="convolutional-kernel-network-in-depth-"> <a id="convolutional-kernel-network-in-depth"></a>Convolutional Kernel Network in-depth üîé</h2> <h3 id="mathematical-insights-and-computability">Mathematical insights and computability</h3> <p>Kernel trick here, kernel trick there‚Ä¶ But can we really compute this kernel trick in practice ?</p> <p>Let us define mathematically an image as a mapping \(I_0 : \Omega_0 \to \mathbb{R}^{3}\) (as an image has \(3\) color channels). If \(\mathbf{x}\) and \(\mathbf{x}'\) are two patches extracted from \(I_0\) we can get \(\varphi_1(\mathbf{x})\) and \(\varphi_1(\mathbf{x}')\), their representation in \(\mathcal{H}\), thanks to the kernel trick ! But, \(\mathcal{H}\) is an <strong><em>infinite</em></strong> dimensional space, so how to deal with it in practice? <img class="emoji" title=":dizzy_face:" alt=":dizzy_face:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f635.png" height="20" width="20"></p> <p>No panic, our friend Nystr√∂m is here to help! Nystr√∂m‚Äôs method aims to approximate \(\varphi_1(\mathbf{x})\) and \(\varphi_1(\mathbf{x}')\) by their projection \(\psi_1(\mathbf{x})\) and \(\psi_1(\mathbf{x}')\) onto a <strong><em>finite</em></strong> dimensional subspace \(\mathcal{F}\) (see the figure below).</p> <figure> <picture> <img src="/assets/img/blog_ckn/Nystrom.png" class="img-fluid rounded z-depth-0" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>The subspace \(\mathcal{F}\) is defined as \(\mathcal{F} = \text{span}(z_1,\dots,z_p)\), where \((z_i)_{i\in\{1\dots p\}}\) are anchor points, of unit-norm. \(Z = \{z_1,\dots,z_p\}\) are the parameters of the layer in the sense that optimizing the layer means optimizing \(\mathcal{F}\). The subspace \(\mathcal{F}\) can be optimized in both a <em>supervised</em> (with backpropagation rules) or an <em>unsupervised</em> way (by minimzing projection residuals with spherical KMeans), see <d-cite key="mairal2016endtoend"></d-cite>.</p> <h3 id="the-convolutional-kernel-network">The Convolutional Kernel Network</h3> <p>We can therefore construct our Convolutional Kernel Layer in three steps.</p> <ul> <li>We extract patches \(\mathbf{x}\) from the image \(I_0\). <details> <summary>Patch Extraction</summary> <pre><code class="language-python">def extract_2d_patches(self, x):
      h, w = self.filter_size
      batch_size, C, _, _ = x.shape
      unfolded_x = np.lib.stride_tricks.sliding_window_view(x, (batch_size, C, h, w))
      unfolded_x = unfolded_x.reshape(-1, self.patch_dim)
      return unfolded_x
  
  def sample_patches(self, x_in, n_sampling_patches=1000):
      patches = self.extract_2d_patches(x_in)
      n_sampling_patches = min(patches.shape[0], n_sampling_patches)
      patches = patches[:n_sampling_patches]
      return patches</code></pre></details> </li> <li>We normalize and convolve them as \(\lVert \mathbf{x} \rVert \kappa \left( Z^\top \displaystyle\frac{\mathbf{x}}{||\mathbf{x}||} \right)\) and compute the approximation as \(\psi(x) = \lVert \mathbf{x} \rVert\kappa\left(Z^\top Z\right)^{-1/2}\kappa\left(Z^\top \displaystyle\frac{\mathbf{x}}{||\mathbf{x}||}\right)\) by applying the linear transform \(\kappa\left(Z^\top Z\right)^{-1/2}\) at every pixel location, <details> <summary>Convolutional Layer</summary> <pre><code class="language-python">def conv_layer(self, x_in):
      patch_norm = np.sqrt(np.clip(conv2d_scipy(x_in**2, self.ones, bias=None,
              stride=1, padding=self.padding, dilation=self.dilation,
              groups=self.groups), a_min=EPS, a_max=None))
      x_out = conv2d_scipy(x_in, self.weight, self.bias, (1,1),
                      self.padding, self.dilation, self.groups)
      x_out = x_out / np.clip(patch_norm, a_min=EPS, a_max=None)
      x_out = patch_norm * self.kappa(x_out)
      return x_out
  
  def mult_layer(self, x_in, lintrans):
      batch_size, in_c, H, W = x_in.shape
      x_out = np.matmul(
          np.tile(lintrans, (batch_size, 1, 1)), 
          x_in.reshape(batch_size, in_c, -1))
      return x_out.reshape(batch_size, in_c, H, W)</code></pre></details> </li> <li> <p>We compute the pooling operations. Note that gaussian linear pooling is defined as</p> \[\begin{equation*} \displaystyle I_1(x) = \int_{\mathbf{x}'\in\Omega_0} M_1(x') \text{e}^{-\beta\lVert \mathbf{x}-\mathbf{x}'\rVert_2^2}\text{d}\mathbf{x}' \end{equation*}\] <p>where \(M_1\) is the ‚Äúfeature map‚Äù after the second point operation. That is why, we can interpret the pooling operation as a ‚Äúconvolution‚Äù operation. </p> <details> <summary>Pooling Layer</summary> <pre><code class="language-python">def pool_layer(self, x_in):
      if self.subsampling &lt;= 1:
          return x_in
      x_out = conv2d_scipy(x_in, self.pooling_filter, bias=None, 
          stride=self.subsampling, padding=self.subsampling, 
          groups=self.out_channels)
      return x_out</code></pre></details> </li> </ul> <p>Here is a global figure that summarizes all these operations, and thus the construction of a Convolutional Kernel Layer.</p> <figure> <picture> <img src="/assets/img/blog_ckn/CKN.png" class="img-fluid rounded z-depth-0" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>After these operations, we have constructed a ‚Äúfeature map‚Äù \(I_1 : \Omega_1 \to \mathbb{R}^{p_1}\), that can be re-used. We can now build a <strong>Convolutional Kernel Network</strong> by stacking Convolutional Kernel Layers, and we will have a <em>representation</em> of the image at the output.</p> <h2 id="cnn-vs-ckn-Ô∏è">CNN vs. CKN ‚öîÔ∏è</h2> <h3 id="overview">Overview</h3> <p>In <d-cite key="bietti2018group"></d-cite>, it is shown that CKNs contain a large class of CNNs with smooth homogeneous activation functions.</p> <figure> <picture> <img src="/assets/img/blog_ckn/CNN.png" class="img-fluid rounded z-depth-0" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>The similarities and differences between CKN and CNN are well illustrated in the two previous figures.</p> <p>On the one hand, A CNN of \(L\) layer can be represented by its output \(f_{\text{CNN}}(\mathbf{x})\), if \(\mathbf{x}\) is the input, as :</p> \[\begin{equation*} f_{\text{CNN}}(\mathbf{x}) = \gamma_L(\sigma_L(W_L\dots \gamma_2(\sigma_2(W_2\gamma_1(\sigma_1(W_1\mathbf{x}))\dots)) \end{equation*}\] <p>where \((W_k)_k\) represent the convolution operations, \((\sigma_k)_k\) are pointwise non-linear functions, (e.g., ReLU), and \((\gamma_k)_k\) represent the pooling operations (see <d-cite key="paulin2016convolutional"></d-cite>).</p> <p>On the other hand, A CKN of \(L\) layer can be represented by its output \(f_{\text{CKN}}(\mathbf{x})\), if \(\mathbf{x}\) is the input, as :</p> \[\begin{equation*} f_{\text{CKN}}(\mathbf{x}) = \gamma_L(\sigma_L(W_L(P_L\dots \gamma_2(\sigma_2(W_2(P_2(\gamma_1(\sigma_1(W_1(P_1(\mathbf{x}))\dots)) \end{equation*}\] <p>where \((P_{k})_{k}\) represent the patch extractions, \((W_{k})_{k}\) the convolution operations, \((\sigma_{k})_{k}\) the kernel operations (which allows us to learn non-linearity in the RKHS), and \((\gamma_{k})_{k}\) the pooling operations.</p> <h2 id="getting-your-hands-dirty-Ô∏è">Getting your hands dirty üñ•Ô∏è</h2> <p>In this section, we discuss how to reimplement the key components of the CKN to better understand how things work.</p> <h3 id="modern-implementation">Modern Implementation</h3> <p>The CKN architecture can be implemented using modern deep learning frameworks such as <code class="language-plaintext highlighter-rouge">PyTorch</code>, <code class="language-plaintext highlighter-rouge">TensorFlow</code> or <code class="language-plaintext highlighter-rouge">JAX</code>. For practical usage, the original implementation can be found <a href="https://github.com/claying/CKN-Pytorch-image" rel="external nofollow noopener" target="_blank">here</a>.</p> <h3 id="stonage-ml">Stonage ML</h3> <p>To better understand how things work, we decided to reimplement the CKN architecture without using modern Deep Learning frameworks. It saves you the burden of reading hundreds of documentation pages, but also has its disadvantages notably regarding computational efficiency. We provide our open-source implementation from scratch <a href="https://github.com/ozekri/CKN_from_Scratch" rel="external nofollow noopener" target="_blank">here</a>.</p> <h4 id="autodiff">Autodiff</h4> <p>At layer \(k\),</p> \[\begin{equation*} \min_{\mathbf{W} \in \mathbb{R}^{p_k \times \lvert\Omega_k\rvert}} \frac{1}{n} \sum_{i=1}^n \mathcal{L}( y_i, \langle \mathbf{W} , I_{k}^i \rangle ) + \frac{\lambda}{2} \lVert \mathbf{W} \rVert_{\text{F}}^2 \end{equation*}\] <p>where \(\lVert \cdot \rVert_{\text{F}}\) is the Frobenius norm that extends the Euclidean norm to matrices, and, with abuse of notation, the maps \(I_{k}^i\) are seen as matrices in \(\mathbb{R}^{p_k \times \lvert\Omega_k\rvert}\). Then, the supervised convolutional kernel network formulation consists of jointly minimizing with respect to \(\mathbf{W} \in \mathbb{R}^{p_k \times \lvert\Omega_k\rvert}\) and with respect to the set of filters \(\mathbf{Z}_1,\ldots,\mathbf{Z}_L\), whose columns are constrained to be on the Euclidean sphere.</p> <div style="display: flex; justify-content: center;"> <blockquote class="twitter-tweet"> <p lang="en" dir="ltr">Backprop in neural-networks is reverse mode auto-diff applied to a simple linear computational graph. The simplicity of the resulting algorithm somehow overshadows the power and non-triviality of applying auto-diff to complex (e.g. recursive) graphs. <a href="https://t.co/5op8P7oYrE" rel="external nofollow noopener" target="_blank">https://t.co/5op8P7oYrE</a> <a href="https://t.co/ETafufgGqa" rel="external nofollow noopener" target="_blank">pic.twitter.com/ETafufgGqa</a></p>‚Äî Gabriel Peyr√© (@gabrielpeyre) <a href="https://twitter.com/gabrielpeyre/status/956932467092574213?ref_src=twsrc%5Etfw" rel="external nofollow noopener" target="_blank">January 26, 2018</a> </blockquote> <script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </div> <p>For implementation from scratch details, see this really simple <a href="https://e-dorigatti.github.io/math/deep%20learning/2020/04/07/autodiff.html" rel="external nofollow noopener" target="_blank">blog post</a> from <a href="https://e-dorigatti.github.io/" rel="external nofollow noopener" target="_blank">Emilio Dorigatti</a>‚Äôs website.</p> <h4 id="convolutional-operations">Convolutional operations</h4> <p>Little-known fact: <a href="https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">torch.conv2D</code></a> computes a <a href="https://en.wikipedia.org/wiki/Cross-correlation" rel="external nofollow noopener" target="_blank">cross-correlation</a>, not a <a href="https://en.wikipedia.org/wiki/Convolution" rel="external nofollow noopener" target="_blank">convolution</a> (yeah, the name is confusing! <img class="emoji" title=":weary:" alt=":weary:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f629.png" height="20" width="20">). But what is the difference? The discrete convolution operator \(\ast\) between two functions \(g\) and \(h\) is defined as</p> \[\begin{equation*} (g \ast h)[n]=\sum_{m=-\infty}^{\infty} g[m] h[n-m] \end{equation*}\] <p>whereas the discrete cross-correlation operator \(\circledast\) is defined as</p> \[\begin{equation*} (g \circledast h)[n]=\sum_{m=-\infty}^{\infty} \overline{g[m]} h[n+m] \end{equation*}\] <p>where \(\overline{g[m]}\) denotes the complex conjugate of \(g[m]\). It‚Äôs subtle, but in the case of images, cross-correlation requires one less ‚Äúimage flipping‚Äù than convolution because of the minus sign in \(h[n-m]\). Given the number of convolutions we‚Äôre going to calculate, if we can spare ourselves an ‚Äúimage flip‚Äù each time, we‚Äôll do it! What‚Äôs more, as the filter parameters are learnable, it doesn‚Äôt matter if we choose cross-correlation rather than convolution.</p> <p>That being said, let‚Äôs underline the fact that accelerating the correlation operations is crucial, as it is very much part of the framework. In fact, we use correlations for convolutional layers, but we‚Äôve also implemented linear pooling as a correlation! These operations will be performed so frequently that, with a from scratch implementation, it‚Äôs absolutely essential to parallelize the process, to make it run much faster on GPUs.</p> <h4 id="parallelization-Ô∏è">Parallelization ‚õ∑Ô∏è</h4> <p>We‚Äôre not allowed to use <a href="https://pytorch.org/docs/stable/generated/torch.nn.functional.conv2d.html" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">torch.nn.functional.conv2d</code></a>, so to parallelize <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.correlate2d.html#scipy.signal.correlate2d" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">scipy.signal.correlate2d</code></a>, we‚Äôre left with two solutions.</p> <h6 id="use-cupy">Use CuPy!</h6> <p><a href="https://cupy.dev/" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">CuPy</code></a> is an open source library for GPU-accelerated computing with Python programming language. <code class="language-plaintext highlighter-rouge">CuPy</code> shares the same API set as <code class="language-plaintext highlighter-rouge">NumPy</code> and <code class="language-plaintext highlighter-rouge">SciPy</code>, allowing it to be a drop-in replacement to run NumPy/SciPy code on GPU.</p> <p>On top of that, <code class="language-plaintext highlighter-rouge">CuPy</code> has its own implementation of <code class="language-plaintext highlighter-rouge">scipy.signal.correlate2d</code> <a href="https://docs.cupy.dev/en/latest/reference/generated/cupyx.scipy.signal.correlate2d.html" rel="external nofollow noopener" target="_blank">here</a>, and it performs superbly. See the code below for comparison with the original one, and <code class="language-plaintext highlighter-rouge">torch.nn.functional.conv2d</code>.</p> <details><summary>Execution Time</summary> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">timeit</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">cupy</span> <span class="k">as</span> <span class="n">cp</span>
<span class="kn">from</span> <span class="n">scipy</span> <span class="kn">import</span> <span class="n">signal</span>
<span class="kn">from</span> <span class="n">cupyx.scipy.signal</span> <span class="kn">import</span> <span class="n">correlate2d</span> <span class="k">as</span> <span class="n">cupyx_correlate2d</span>

<span class="c1"># Creating a test image and kernel
</span><span class="n">image</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="mi">5000</span><span class="p">,</span> <span class="mi">5000</span><span class="p">)</span>
<span class="n">kernel</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

<span class="c1"># Correlation calculation with scipy.signal.correlate2d
</span><span class="n">start_time</span> <span class="o">=</span> <span class="n">timeit</span><span class="p">.</span><span class="nf">default_timer</span><span class="p">()</span>
<span class="n">result_scipy</span> <span class="o">=</span> <span class="n">signal</span><span class="p">.</span><span class="nf">correlate2d</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="sh">'</span><span class="s">valid</span><span class="sh">'</span><span class="p">)</span>
<span class="n">scipy_time</span> <span class="o">=</span> <span class="n">timeit</span><span class="p">.</span><span class="nf">default_timer</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Execution time with scipy.signal.correlate2d :</span><span class="sh">"</span><span class="p">,</span> <span class="n">scipy_time</span><span class="p">)</span>

<span class="c1"># Correlation calculation with torch.nn.functional.conv2d
</span><span class="n">start_time</span> <span class="o">=</span> <span class="n">timeit</span><span class="p">.</span><span class="nf">default_timer</span><span class="p">()</span>
<span class="n">result_torch</span> <span class="o">=</span> <span class="nf">torch_correlate2d</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="sh">'</span><span class="s">valid</span><span class="sh">'</span><span class="p">)</span>
<span class="n">torch_time</span> <span class="o">=</span> <span class="n">timeit</span><span class="p">.</span><span class="nf">default_timer</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Execution time with torch.nn.functional.conv2d :</span><span class="sh">"</span><span class="p">,</span> <span class="n">torch_time</span><span class="p">)</span>

<span class="c1"># Correlation calculation with cupyx.scipy.signal.correlate2d
</span><span class="n">image_gpu</span> <span class="o">=</span> <span class="n">cp</span><span class="p">.</span><span class="nf">asarray</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
<span class="n">kernel_gpu</span> <span class="o">=</span> <span class="n">cp</span><span class="p">.</span><span class="nf">asarray</span><span class="p">(</span><span class="n">kernel</span><span class="p">)</span>
<span class="n">start_time</span> <span class="o">=</span> <span class="n">timeit</span><span class="p">.</span><span class="nf">default_timer</span><span class="p">()</span>
<span class="n">result_cupyx</span> <span class="o">=</span> <span class="nf">cupyx_correlate2d</span><span class="p">(</span><span class="n">image_gpu</span><span class="p">,</span> <span class="n">kernel_gpu</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="sh">'</span><span class="s">valid</span><span class="sh">'</span><span class="p">)</span>
<span class="n">cupyx_time</span> <span class="o">=</span> <span class="n">timeit</span><span class="p">.</span><span class="nf">default_timer</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Execution time with cupyx.scipy.signal.correlate2d :</span><span class="sh">"</span><span class="p">,</span> <span class="n">cupyx_time</span><span class="p">)</span></code></pre></figure> </details> <p>Running the code above produces the following output:</p> <pre><code class="language-python">scipy.signal.correlate2d : 8.6376 seconds
torch.nn.functional.conv2d : 0.1617 seconds
cupyx.scipy.signal.correlate2d : 0.0006 seconds</code></pre> <p>Note that there also exist a <a href="https://jax.readthedocs.io/en/latest/_autosummary/jax.scipy.signal.correlate2d.html" rel="external nofollow noopener" target="_blank">LAX-backend implementation</a> of <code class="language-plaintext highlighter-rouge">scipy.signal.correlate2d</code> in <code class="language-plaintext highlighter-rouge">JAX</code>.</p> <h6 id="use-a-low-level-language">Use a Low-Level Language</h6> <p>You can also implement the function in a low-level language such as C or C++ for better performance, and use a high-level language like Python to call this implementation. In practice, this is what is done in PyTorch. In our work, we re-implemented the <code class="language-plaintext highlighter-rouge">scipy.signal.correlate2d</code> using Nvidia CUDA. We provide below the corresponding implementation.</p> <div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="k">const</span> <span class="err">\</span><span class="o">*</span><span class="n">argv</span><span class="p">[])</span>
<span class="p">{</span>
    <span class="n">string</span> <span class="n">myString</span><span class="p">;</span>

    <span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"input a string: "</span><span class="p">;</span>
    <span class="n">getline</span><span class="p">(</span><span class="n">cin</span><span class="p">,</span> <span class="n">myString</span><span class="p">);</span>
    <span class="kt">int</span> <span class="n">length</span> <span class="o">=</span> <span class="n">myString</span><span class="p">.</span><span class="n">length</span><span class="p">();</span>

    <span class="kt">char</span> <span class="n">charArray</span> <span class="o">=</span> <span class="k">new</span> <span class="kt">char</span> <span class="o">*</span> <span class="p">[</span><span class="n">length</span><span class="p">];</span>

    <span class="n">charArray</span> <span class="o">=</span> <span class="n">myString</span><span class="p">;</span>
    <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">length</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">){</span>
        <span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="n">charArray</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&lt;&lt;</span> <span class="s">" "</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div> <details><summary>CUDA Implementation</summary> <figure class="highlight"><pre><code class="language-cpp" data-lang="cpp"><span class="k">extern</span> <span class="s">"C"</span> <span class="p">{</span>
    <span class="n">__global__</span> <span class="kt">void</span> <span class="n">correlate2d_gpu_kernel</span><span class="p">(</span>
        <span class="kt">float</span><span class="o">*</span> <span class="n">result</span><span class="p">,</span>
        <span class="kt">float</span><span class="o">*</span> <span class="n">image</span><span class="p">,</span>
        <span class="kt">float</span><span class="o">*</span> <span class="n">kernel</span><span class="p">,</span>
        <span class="kt">int</span> <span class="n">image_width</span><span class="p">,</span>
        <span class="kt">int</span> <span class="n">image_height</span><span class="p">,</span>
        <span class="kt">int</span> <span class="n">kernel_width</span><span class="p">,</span>
        <span class="kt">int</span> <span class="n">kernel_height</span><span class="p">)</span> <span class="p">{</span>
        <span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
        <span class="kt">int</span> <span class="n">j</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">y</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">&lt;</span> <span class="n">image_width</span> <span class="o">-</span> <span class="n">kernel_width</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">&amp;&amp;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">image_height</span> <span class="o">-</span> <span class="n">kernel_height</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
            <span class="kt">float</span> <span class="n">sum</span> <span class="o">=</span> <span class="mf">0.0</span><span class="n">f</span><span class="p">;</span>
            <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">ki</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">ki</span> <span class="o">&lt;</span> <span class="n">kernel_width</span><span class="p">;</span> <span class="n">ki</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
                <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">kj</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">kj</span> <span class="o">&lt;</span> <span class="n">kernel_height</span><span class="p">;</span> <span class="n">kj</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
                    <span class="n">sum</span> <span class="o">+=</span> <span class="n">kernel</span><span class="p">[</span><span class="n">ki</span> <span class="o">*</span> <span class="n">kernel_width</span> <span class="o">+</span> <span class="n">kj</span><span class="p">]</span> <span class="o">*</span> <span class="n">image</span><span class="p">[(</span><span class="n">i</span> <span class="o">+</span> <span class="n">ki</span><span class="p">)</span> <span class="o">*</span> <span class="n">image_width</span> <span class="o">+</span> <span class="p">(</span><span class="n">j</span> <span class="o">+</span> <span class="n">kj</span><span class="p">)];</span>
                <span class="p">}</span>
            <span class="p">}</span>
            <span class="n">result</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="p">(</span><span class="n">image_height</span> <span class="o">-</span> <span class="n">kernel_height</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">sum</span><span class="p">;</span>
        <span class="p">}</span>
    <span class="p">}</span>

    <span class="kt">void</span> <span class="nf">correlate2d_gpu</span><span class="p">(</span>
        <span class="kt">float</span><span class="o">*</span> <span class="n">result</span><span class="p">,</span>
        <span class="kt">float</span><span class="o">*</span> <span class="n">image</span><span class="p">,</span>
        <span class="kt">float</span><span class="o">*</span> <span class="n">kernel</span><span class="p">,</span>
        <span class="kt">int</span> <span class="n">image_width</span><span class="p">,</span>
        <span class="kt">int</span> <span class="n">image_height</span><span class="p">,</span>
        <span class="kt">int</span> <span class="n">kernel_width</span><span class="p">,</span>
        <span class="kt">int</span> <span class="n">kernel_height</span><span class="p">)</span> <span class="p">{</span>
        <span class="kt">float</span><span class="o">*</span> <span class="n">d_result</span><span class="p">;</span>
        <span class="kt">float</span><span class="o">*</span> <span class="n">d_image</span><span class="p">;</span>
        <span class="kt">float</span><span class="o">*</span> <span class="n">d_kernel</span><span class="p">;</span>

        <span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_result</span><span class="p">,</span> <span class="p">(</span><span class="n">image_width</span> <span class="o">-</span> <span class="n">kernel_width</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">image_height</span> <span class="o">-</span> <span class="n">kernel_height</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>
        <span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_image</span><span class="p">,</span> <span class="n">image_width</span> <span class="o">*</span> <span class="n">image_height</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>
        <span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_kernel</span><span class="p">,</span> <span class="n">kernel_width</span> <span class="o">*</span> <span class="n">kernel_height</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>

        <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">d_image</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">image_width</span> <span class="o">*</span> <span class="n">image_height</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">),</span> <span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>
        <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">d_kernel</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">kernel_width</span> <span class="o">*</span> <span class="n">kernel_height</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">),</span> <span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>

        <span class="n">dim3</span> <span class="n">blockSize</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">);</span>
        <span class="n">dim3</span> <span class="n">gridSize</span><span class="p">((</span><span class="n">image_width</span> <span class="o">-</span> <span class="n">kernel_width</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">blockSize</span><span class="p">.</span><span class="n">x</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">blockSize</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">image_height</span> <span class="o">-</span> <span class="n">kernel_height</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">blockSize</span><span class="p">.</span><span class="n">y</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">blockSize</span><span class="p">.</span><span class="n">y</span><span class="p">);</span>

        <span class="n">correlate2d_gpu_kernel</span><span class="o">&lt;&lt;&lt;</span><span class="n">gridSize</span><span class="p">,</span> <span class="n">blockSize</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">d_result</span><span class="p">,</span> <span class="n">d_image</span><span class="p">,</span> <span class="n">d_kernel</span><span class="p">,</span> <span class="n">image_width</span><span class="p">,</span> <span class="n">image_height</span><span class="p">,</span> <span class="n">kernel_width</span><span class="p">,</span> <span class="n">kernel_height</span><span class="p">);</span>

        <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">d_result</span><span class="p">,</span> <span class="p">(</span><span class="n">image_width</span> <span class="o">-</span> <span class="n">kernel_width</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">image_height</span> <span class="o">-</span> <span class="n">kernel_height</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">),</span> <span class="n">cudaMemcpyDeviceToHost</span><span class="p">);</span>

        <span class="n">cudaFree</span><span class="p">(</span><span class="n">d_result</span><span class="p">);</span>
        <span class="n">cudaFree</span><span class="p">(</span><span class="n">d_image</span><span class="p">);</span>
        <span class="n">cudaFree</span><span class="p">(</span><span class="n">d_kernel</span><span class="p">);</span>
    <span class="p">}</span>
<span class="p">}</span></code></pre></figure> </details> <h2 id="acknowledgments-"> <a id="acknowledgments"></a>Acknowledgments üôèüèæ</h2> <p>For any further questions, please feel free to leave a comment or contact the authors by mail!</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/2024-04-22-ckn.bib"></d-bibliography> <div id="giscus_thread" style="max-width: 800px; margin: 0 auto;"> <script>let giscusTheme=determineComputedTheme(),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"logB-research/logB-research.github.io","data-repo-id":"","data-category":"Comments","data-category-id":"","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> ¬© Copyright 2024 logB </div> </footer> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>